---
title: "Zusatztutorium Mathe A WS19/20"
author: "Anton Hanke, Maximillian Kohnen, Felix Schnabel"
date: "Fragestunde: 27/11/19"
header-includes:
   - \usepackage{stmaryrd}
output:
  html_document:
    toc: TRUE
    toc_depth: 3
    toc_float: TRUE
  pdf_document:
    toc: TRUE
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Mathematische Logik

## Aussagen

Wohlformulierte beschreibende S?tze nennt man "Aussagen" (Behauptungen, Mitteilungen). ( (Franz von Kutzschera und Alfred Breitkopf, Einf?hrung in die moderne Logik, 7. neu bearbeitete Auflage, Freiburg im Breisgau, 2000).)

Aussagen besitzen Eigenschaften, welche logisch relevant sind.

Aussagen wären zum Beispiel:

(1) Der Mars hat eine ähnliche Atmosphäre wie die Erde.

(2) Der Mars bewegt sich, abgesehen von Bahnstörungen, auf einer elliptischen Bahn um die Sonne.

Die Aussagen (1) und (2) besitzen einen Wahrheitswert.

Die Aussage (1) ist eine falsche Aussage, die Aussage (2) ist wahr.


### Implikationen

Eine Implikation beschreibt eine Folgerung. 

Eine Implikation w?re zum Beispiel:

 $$(1) \Rightarrow (2)$$ 
 
Eine Implikation hat so wie eine Aussage einen Wahrheitswert.
## Quantoren

$\forall$ : Für alle

$\exists$ : Es existiert mindestens ein

$\exists!$ : Es exsitiert genau ein

$\neg\exists$: Es exsitiert kein


## Beweise
Um etwas Mathematisch zu Beweisen gibt mehrere Ansätze. Die wichtigsten sind:

- **Direkter Beweis:**
  Wir beweisen A $=>$ B mittels A $=>$ A' $=>$ A'' $=>$ B
  
  
  
    Bsp: Sei $n\in\mathbb{N}$ Dann gilt: n ungerade => $n^2$ auch ungerade
  
    n ungerade => $\exists m \in \mathbb{N}: 2m+1=n$ 
    
    =>$(2m+1)^2 = 4m^2+4m+1 = 2(2m^2+2m)+1 => n^2$ 
    
    mit $2(2m^2+2m)\in \mathbb{N}$ und gerade
    
    Da $n^2 = 2(2m^2+2m)$ **+1** ist auch $n^2$ eine ungerade Zahl.
    
- **Kontraposition**
  Anstatt A => B z.z., zeigt man $\neg B => \neg A$
  
  
  
    Bsp: Sei $n\in\{k^2|k\in\mathbb{N}\}$ Dann gilt:
    
    $n$ gerade $=>$ $\sqrt n$ gerade
    
    Kontraposition:
    
    $\sqrt n$ gerade $->$ n ungerade
    
    $\forall m \in \mathbb{N}:n=k^2 => k^2$ gerade $=> k \ gerade$
    
- **Indirekter Beweis (Widerspruchsbeweis)**
  Wir nehmen $A => B$, dann können wir sagen wenn $\neg B \wedge A => \neg A$ an und zeigen, dass es zum Widerspruch führt

    $\neg(A \wedge (\neg B)) <=> A => B$
  
    Bsp: Für $A= B = \{-1,1\}$ gilt \ $min(A)*min(B) = min (A*B)$ mit $A*B := \forall a \in A \wedge b \in B, A*B= a*b$
    
    $min(A)=-1, min (B) =-1 , min(A*B) = -1$
    
    $min(A)*min(B)= -1*-1 = 1 \neq -1 = min(A*B)$
    
    

### Beweis über vollständige Induktion

Bei der Vollständigen Induktion wird für eine finite Definitionsmenge die Aussage bewiesen.

Zu zeigen sind:

- **Induktionsanfang**: Die Aussage gilt für das erste Element / die ersten X Element

- **Induktionsannahme**: **Wir nehmen an:** die Aussage gilt für beliebige und feste Elemente der Menge

- **Induktionschritt** : Wir beweisen, dass für das nächste Element / die nächsten Elemente die Bedingung auch erfüllt wird mittels verwendung der Induktionsannahme

-Bsp: 

$\forall n\ge1$ gilt $\sum_{k=1}^{n} k=\frac{n(n+1)}{2}$

-**Induktionsanfang**: Wir zeigen, dass die Formel für $n=1$ richtig ist.

$\sum_{k=1}^{1} k=1 <=> \frac{1(1+1)}{2}=\frac{2}{2}=1$

-**Induktionsannahme**: Wir nehmen an, $\sum_{k=1}^{n} k=\frac{n(n+1)}{2}$ gilt für alle *feste* und *beliebiege* n.

-**Induktionsschritt**
Wir zeigen, dass $\sum_{k=1}^{n} k=\frac{n(n+1)}{2}$ für $n -> n+1$ gilt.

$\sum_{k=1}^{n+1} k=(n+1)+\sum_{k=1}^{n} k$

mittels Induktionsannahme nehmen wir an:

$\sum_{k=1}^{n} k=\frac{n(n+1)}{2}$

somit ist 

$\sum_{k=1}^{n+1} k=(n+1)+\sum_{k=1}^{n} k=\sum_{k=1}^{n} k=(n+1)+\frac{n(n+1)}{2}=\frac{2(n+1)}{2}\frac{n(n+1)}{2}$

- ausklammern von (n+1)

$=\frac{(n+2)*(n+1)}{2}=\frac{((n+1)+1)*(n+1)}{2}$ was der Form $\sum_{k=1}^{n} k=\frac{n(n+1)}{2}$ für $n -> n+1$ entspricht

Wir haben mittels Induktionsannahme bewiesen, dass für jedes Element $n$ die gleichung für das darrauffolgende Element $n+1$ gilt. Da die Gleichung für das erste Element $n=1$ gilt und für alle darauffolgenden gilt: $$\sum_{k=1}^{n} k=\frac{n(n+1)}{2} \ \ \ \ \  \forall n\ge1$$

# Mengen und algebraische Struckturen
Mengen sind Zusammenfassungen bestimmter, wohlunterscheidbarer Objekte.
Für jedes Objekt ist eine klare zuordnung zur Menge erkentlich

-------------

Mengen sind keine Aussagen!!

-------------


## sonder mengen & Mengen Relationen
- $\emptyset \subset \mathbb{N} \subset \mathbb{Z} \subset \mathbb{Q} \subset \mathbb{R} \subset \mathbb{C}$
- $A \subset B$ !Aussage!
- $A \cap B$
- $A \cup B$
- $A\setminus B\quad \wedge \quad B\setminus A$
- $A \times B = \left\{ (a,\,b): a \in A, b \in B\right\}$

## Abbildungen
$$f: A \rightarrow B$$

- A $=$ Definitionsmenge, von hier bilden wir ab.
- B $=$ Zielmenge, hierdrauf wird abgebildet.
- Bildmenge: $\subset B$ welche sich aus $f(A)$ ergibt.

1. Injektive Abbildung: $\forall i\in B|~~ \# (a \in A) \leq 1 : f(a) \rightarrow i$
2. Surjektive Abbildung: $\forall i \in B|~~\# (a \in A) \geq 1 : f(a) \rightarrow i$
3. Bijektive Abbildung: $\forall i \in B|~~ \# (a \in A) = 1 : f(a) \rightarrow i \qquad$ (1. $\wedge$ 2.)

### Gruppen $(G, \oplus)$

- **Abgeschlossenheit** $$a \in G, b \in G : a \oplus b \in G$$
- **Assoziativität** $$(b\oplus a) \oplus c = a \oplus (b \oplus c)$$
- **Neutrales Element** $D_{0}$ $$\exists e \in G, \forall a \in G : a \oplus e = a$$
- **Inverses Element** $$\forall a \in G, \exists \bar{a} \in G: a \oplus \bar{a} = e$$
- **Kommultativität** (abelsche Gruppe):$$\forall a \in G, \forall b \in G: a \oplus b = b \oplus a$$

### Ringe $(M, \oplus, \otimes)$

1. $(M, \oplus)$ ablesche Gruppe
2. $a \otimes ( b \otimes c) = (a \otimes b) \otimes c$ assoziativität gegeben.
3. Distributiv: $\forall a,b,c \in M : a \otimes (b\oplus c) = a \otimes b \oplus a \otimes c$.

- Kommutativ wenn: $a \otimes b = b \otimes a$
- unitär wenn: $\exists 1 \in M : a \otimes 1 = 1 \otimes a = a$.

### Körper $(K, \oplus, \otimes)$
1. $(K, \oplus)$ is abelsche Gruppe mit $D_0 = 0$.
2. $(K \setminus \{0\}, \otimes)$ abelsche Gruppe mit $D_0 = 1$.
3. Distributivgesetz gilt.

- **Unterschied zu Ringen:** $(M, \otimes)$ keine abelsche Gruppe, kein Inverses!

## Vektorrechnung
Vektoren sind tupel mit $n$ elementen ($n = \dim{V}$).  
Sie erfüllen alle bedingungen eines Körpers und lassen sich
nicht mit sich selbst multiplizieren.

- Linearkombination:
$$\vec{z} = \sum _{ i = 1 } ^ k \mu _i \vec{x} _i \in V$$
Hierbei sind $\mu$ skalare $(\mu \in \mathbb{R})$

- Skalarprodukt:
"Vektor multiplikation".  
$$\mathbb{R}^n \mathbb{R}^n = \mathbb{R}$$
Relevant ist, das beide Vektoren gleiche Dimension haben.  
$$ \vec{v} \cdot \vec{w} = \sum _{i = 1} ^n v_i w_i \in \mathbb{R}$$

- Vektor betrag:
$$|\vec{v}|^2 = \vec{v}\cdot\vec{v}$$
$$\Rightarrow |\vec{v}| = \sqrt{\sum_{i = 1} ^n v_i^2}$$
Ein Vektor lässt sich normieren mit: $\vec{e}_v = \frac{\vec{v}}{|\vec{v}|}$.
In $\mathbb{R}^{2}$ gilt: $\vec{e} = \left(\begin{array}{c}\cos \alpha\\ \sin \alpha \end{array}\right)$

- Winkel zwischen Vektoren:  
  Sind vektoren ortogonal ($\alpha = 90^{\circ}$) gilt: $\vec{u}\cdot\vec{v} = 0 \Leftrightarrow \vec{u} \bot \vec{v}$  
  Allgemein berechnet sich der Winkel mit:
  $$\vec{u}\cdot\vec{v} = |\vec{u}||\vec{v}|\cos\theta$$


### Basis eines Vektorraums
Die Basis eines Vektorraums ist die Menge an vektoren,
mit welchen sich über Linearkombination jeder Vektor
im Vektorraum berechnen lässt, sie wird der span des Raums gennant:
$$\forall \vec{v} \in V: \exists \lambda_{1}, \ldots, \lambda_{k} \in \mathbb{R}: \vec{v}=\sum_{i=1}^{n} \lambda_{i} \vec{e}_{i}$$  
Die Vektoren dieser Basis spannen den Vektorraum auf und werden als $\text{span}{V}$ bezeichent, wobei $V :\Leftrightarrow \{\vec{v}_i,\dots, \vec{v}_k\} \in \mathbb{R}^{n}$

Drei relevante Basen sind:

1. Kanonische Basis: $\mathbb{R}^{n} \left\{ \vec{e}_{1} = \left( 1,\dots,0 \right), \vec{e}_{i} = (0,\dots, 1,\dots, 0), \vec{e}_{n} = \left( 0,\dots,1 \right)\right\}\quad i = 1, \dots, n$
2. normierte Basis: $\left\{ \vec{v}_{i} \in X \right\}: |\vec{v}_{i}| = 1~~ \forall i = 1, \dots, n$
3. orthogonale Basis: $\left\{ \vec{v}_{i} \in X \right\}: \vec{v}_{i} \cdot \vec{v}_{j} = 0~~\forall i,j = 1, \dots, n$

Alle Vektoren der Basis des Vektorraums müssen linear unabhängig voneinander sein:
$$\sum_{i=1}^{r} \lambda_{1} \vec{v}_{1}+\ldots_{i}+\lambda_{r} \vec{v}_{r}^{2}=\vec{O} \Leftrightarrow \lambda_{i}=0 \quad i=1, \ldots, r$$
Lineare Abbhängigkeit ist gegeben, wenn $\exists \lambda \neq 0$ sodass $\lambda\vec{v}_{1}\cdot\lambda\vec{v}_{2} = \vec{0}$.  

Die Dimension des (aufgespannten) Vektorraums entspricht der
Anzahl an Basis oder Span Vektoren.
$$\dim V = \text{span} \left( V \right)$$



# Komplexe Zahlen und trignometrische Funktionen

## Darstellungen Komplexer Zahlen

### Kartesische Darstellung

### Polarkoordinaten Darstellung

### Euler Darstellung

## Rechenoperationen Komplexer Zahlen

## Trigonometrische Funktione

### Geometrische Interpretation

### Eigenschaften und wichtige Gleichungen

### Wichtige Werte

# Matrizen und Lineare Algebra
Lineare Gleichungssysteme stellen sich wie folgt da:
\[\left\{
\begin{array}{lcll}
    \lambda_{1,\:1}~ x_1 + 
    \lambda_{1,\:\dots }~ x_{\dots} + 
    \lambda_{i,\:1}~ x_i &=& b_1 & \text{Gl.}~ 1 \\
    \lambda_{1,\:\dots}~ x_1 + 
    \lambda_{\dots ,\:\dots}~ x_{\dots} + 
    \lambda_{i,\:\dots }~ x_{i} &=& b_{\dots} & \text{Gl.}~\dots \\
    \lambda_{1,\:j}~ x_1 + 
    \lambda_{\dots,\:j}~ x_{\dots} + 
    \lambda_{i,\:j}~ x_i &=& b_k & \text{Gl.}~ k
\end{array}
\right.\]
Dies lässt sich wie folgt umschreiben: $$Ax = b$$
Dabei sind $x$ und $b$ vectoren.
$A$ ist eine Matrix.
$$ A = \begin{pmatrix}
    \lambda_{1,\:1} & \lambda_{1,\:\dots } & \lambda_{i,\:1} \\
    \lambda_{1,\:\dots} & \lambda_{\dots ,\:\dots} & \lambda_{i,\:\dots } \\
    \lambda_{1,\:j} & \lambda_{\dots,\:j} & \lambda_{i,\:j} \\
\end{pmatrix}$$
Eine Matrix wird durch ihre Dimensionen beschreiben:

- $m$: \# Zeilen
- $n$: \# Spalten

**_Die Lösungsmenge eines LGS ist durch äquivalente umformungen unverändert._**

## Matrixrechung
Matrizen haben folgende Eigenschaften:

1. Assoziativ
2. Dissoziativ
3. _nicht_ kommutativ!

### Matrix addition/subtraktion
Matrizen müssen identische Dimensionen haben.
Addition der einzelnen Elemente aufeinander.

### Matrix multiplikation
Kriterium: innere Dimensionen gleich.
\[\underset{m\times n}{A} \times \underset{n \times p}{B} = \underset{m \times p}{C}\]
An sich ergibt sich die Ergebnismatrix aus Skalarprodukten der
Zeilen und Spalten der Inputmatrizen.
\[
\begin{pmatrix}
    &&\\
    i_1&i_{C}&i_k\\
    &&\\
\end{pmatrix}
\begin{pmatrix}
    &j_i&\\
    &j_{C}&\\
    &j_k&\\
\end{pmatrix}
\begin{pmatrix}
    &&\\
    &C_{ij}&\\
    &&\\
\end{pmatrix}
\Longleftrightarrow
C_{i,\: j} = \sum_{k = 1}^{n} a_{ik} \cdot b_{jk}
\]

Das neutrale Element der Matrix multiplikation ist die Identitätsmatrix,
eine Diagonalmatrix, mit der Determinante 1:
$$I=
\begin{pmatrix}
    1 & 0 & 0\\
    0 & 1 & 0\\
    0 & 0 & 1\\
\end{pmatrix}
$$

#### Linearkombinationen für Berechnungen:
1. Spalten:  
    $$j_C = x_B^{\: j}\lambda_A + y_B^{\: j} \theta_A + z_B^{\: j} \mu_A$$
    Die Spalte $j$ von $C$ ergibt sich aus der Vektorsumme der Spalten von
    $A$ multipliziert mit den Elementen in der $j$ten Spalte von $B$.
2. Zeilen:
   $$i_C = x_A^{\: i} \lambda_B + y_A^{\: i} \theta_B + z_A^{\: i} \mu_B$$
   Die Zeile $i$ von $C$ ergibt sich aus der Vektersumme der Zeilen von
   $B$ multipliziert mit den Elementen in der $i$ten Zeile von $A$.

### Matrix transposition
"Rotation einer matrix":  
\[ \underset{m \times n}{A} =
\begin{pmatrix}
    a_{1,1} & \cdots & a_{1,n} \\
    \vdots  &        & \vdots  \\
    a_{m,1} & \cdots & a_{m,n} \\
\end{pmatrix} \longrightarrow
\underset{m \times n }{A}^{T} =
\begin{pmatrix}
    a_{1,1} & \cdots & a_{m,1} \\
    \vdots  &        & \vdots  \\
    a_{1,n} & \cdots & a_{m,n} \\
\end{pmatrix}
\]
Spiegelung um die Diagonale.
```{r, echo = F}
matrix(seq(1,9),nrow = 3)
t(matrix(seq(1,9),nrow = 3))
```
Wenn gilt: $A = A^T$ so ist die Matrix Spiegelsymmetrisch.  
Diagonalmatrizen immer Spiegelsymmetrisch.

### Matrix inverse
Die Inverse Matrix ist das Inverse Element eines Elements in dem Körper
der Matrix Multiplikation.  
Es gilt: $A^{-1} A = AA^{-1} = I$

------------

Nur, aber nicht alle, quadratischen Matrizen sind invertierbar.

------------

Matrizen sind invertierbar, wenn sie nicht-Singulär sind.
$$\exists A \,|\,\det{A} \neq 0 \Rightarrow \exists!\, A^{-1} : AA^{-1} = I$$
Demnach sind LGS mit genau einer Lösung lösbar,
wenn die Matrix invertierbar ist.  


### Matrix Diagonalisierung und determinanten
Durch Diagonalisierung (alle Elemente der Matrix _über/unter_ Diagonale $=0$)
lassen sich die **Pivot Elemente** (Elemente auf Diagonale) bestimmen.  
Generel:
$$EA = A'$$
Dabei $E=$ Eliminationsmatrix. Eigenschaften:

- Immer invertierbar
- $\det{E} = 1$
- Lower oder Upper Diagonalmatrix

Die Eliminationsmatrix die Benötigt wird um eine Matrix
vollständig in eine Upper Diagnalmatrix zu überführen ist
die lower Diagonalmatrix der Matrix A.  
$$\underbrace{E'\underbrace{EA}_{A'}}_{A''}$$
Somit:
$$\underbrace{E''}_{\text{under triangel}}A = \overbrace{A''}^{\text{Upper triangel}}$$
Aus den Diagonalmatrizen kann man die **Pivot Elemente** a
$$
\begin{pmatrix}
    \fbox{x} & x & x \\
    0   & \fbox{x} & x\\
    0   & 0 & \fbox{x}\\
\end{pmatrix}
$$

<center>
    $\blacktriangleright$ Beachte Multiplikationsreihenfolge, nicht kummutativ $\blacktriangleleft$  
    $\blacktriangleright$ $E$ sind Einheitsmatrizen und somit 1 auf Diagnoale! ($\det(E) = 1$) $\blacktriangleleft$  
</center>
Die Determinante einer matrix:
$$\det{A} = \prod \text{Pivot Elemente}$$
In einer Matrix mit $\det{A}\neq 0$ gibt es entweder 0 oder $\infty$ viele
Lösungen für Gleichungssysteme.
Die Matrix ist Singulär und hat kein Inverses.

### Spalten und Nullraum

## Eliminationsverfahren
1. Gleichungssystem aufstellen
2. Gleichungen äquivalent umformen, bis eine dieser nurnoch von einer Variable abhängig ist.
   Erlaubte Umformungen:
   - Permutationen (Gleichungen vertauschen)
   - Skalieren von Gleichungen mit $\lambda \neq 0$
   - Linearkombination von Gleichungen
3. Auflösen der Variable.
4. Resubstitution und schrittweise ermittlung der weiteren Variablen.

### Matrix Erweiterung
Erweiterte Matrix aufstellen $(A|b)$:
\[
\left(\left. 
\begin{matrix}
    a_{1,1} & \cdots & a_{1,n} \\
    \vdots  & \ddots & \vdots  \\
    a_{m,1} & \cdots & a_{m,n} \\
\end{matrix}
\right|
\begin{array}{c}b_1\\ b_{\dots}\\ b_m\end{array}
\right)
\]

Multiplikation der erweiterten Matrix mit E (siehe Diagonalisierung, entweder $L$ oder $U$).  
\[
\left(\left.
\begin{matrix}
    \alpha_{1,1} & \cdots & \alpha_{1,n} \\
    0  & \ddots & \vdots  \\
    0 & 0 & \alpha_{m,n} \\
\end{matrix}
\right|\, E \times \,
\begin{array}{c}b_1\\ b_{\dots}\\ b_m\end{array}
\right)
\]
Damit ist das Gleichungssystem durch substitution von unten nach oben lösbar.
So können sowohl nicht Singuläre systeme vollständig gelöst als auch
die Lösungsmengen Singulärer Systeme bestimmt werden.

### Gauß-Jordan-Verfahren
Hat eine Matrix ein Inverses so kann die Eindeutige Lösung mit diesem Berechnet werden:
$$x = b A^{-1}$$
Um das Inverse einer Matrix zu berechnen, kann man eine Erweiterete Matrix von A mit I aufstellen:

\[
\left(\left.~~\overbrace{
\begin{matrix}
    a_{1,1} & \cdots & a_{1,n} \\
    \vdots  & \ddots & \vdots  \\
    a_{m,1} & \cdots & a_{m,n} \\
\end{matrix}\:}^{A}
\,\,\right|\,\,
\overbrace{
\begin{matrix}
    1 & \cdots & 0 \\
    \vdots  & \diagdown & \vdots  \\
    0 & \cdots & 1 \\
\end{matrix}\:}^{I}~~
\right)
\]
In Schritten wird nun die Linke Matrix ($A$) mittels $E$
in eine $I$ umgewandelt.  
Hierbei wird auch immer $I$ mit $E$ multipliziert.  
Erhalten wird:

\[
\left(\left.~~\overbrace{
\begin{matrix}
    1 & \cdots & 0 \\
    \vdots  & \diagdown & \vdots  \\
    0 & \cdots & 1 \\
\end{matrix}\:}^{EA}~~
\,\,\right|\,\,
\overbrace{
\begin{matrix}
    \alpha_{1,1} & \cdots & \alpha_{1,n} \\
    \vdots  & \ddots & \vdots  \\
    \alpha_{m,1} & \cdots & \alpha_{m,n} \\
\end{matrix}\:}^{EI}~~
\right)
\]
Hierbei ist nun: $EI = A^{-1}$ und wir können somit das Gleichungssystem $x = A^{-1}b$
lösen.

## Lösbarkeit
Lösbarkeit von Gleichungssystemen einteilbar in zwei Untergruppen, wenn $A$ quadratisch:

1. $\det(A) \neq 0 \Rightarrow \exists ! A^{-1}$  
   Das LGS hat genau *_eine und nur eine_* lösung.
   Gaus-Jordan Verfahren anwendbar.  
   Alle Spaltenvektoren Linear unabhängig.
2. $\det(A) = 0 \Rightarrow \nexists A^{-1}$  
   Ein Pivot element in $EA = 0$  
   Im LGS gilt:
   - $0 \in Eb \Leftrightarrow \infty \text{ Lsg.}$
   - $0 \notin Eb \Leftrightarrow 0 \text{ Lsg.}$

